<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>radiology_ai.train.models API documentation</title>
<meta name="description" content="Model related utilities" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/atom-one-dark.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<link rel="preconnect" href="https://www.google.com">
<script async src="https://cse.google.com/cse.js?cx=017837193012385208679:pey8ky8gdqw"></script>
<style>
.gsc-control-cse {padding:0 !important;margin-top:1em}
body.gsc-overflow-hidden #sidebar {overflow: visible;}
</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:#555;padding-bottom:.5em;border-bottom:1px solid silver}.homelink:hover{color:inherit}.homelink img{max-width:20%;max-height:5em;margin:auto;margin-bottom:.3em}</style>
<link rel="canonical" href="https://pdoc3.github.io/pdoc/doc/radiology_ai/train/models.html">
<link rel="icon" href="https://pdoc3.github.io/pdoc/logo.png">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>radiology_ai.train.models</code></h1>
</header>
<section id="section-intro">
<p>Model related utilities</p>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L0-L188" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34; Model related utilities &#34;&#34;&#34;

import torch
import numpy as np

from fastai.callback.core import Callback
from fastai.vision.learner import *
from fastcore.foundation import L
from fastai.torch_core import params

try:
    from efficientnet_pytorch import EfficientNet
except ImportError:
    print(
        &#34;EfficientNet models cannot be used because `efficientnet_pytorch` package is not installed&#34;
    )


def efficientNet_split(m):
    return L(
        torch.nn.ModuleList([m._swish, m._bn0, m._conv_stem, m._blocks]),
        torch.nn.ModuleList([m._swish, m._bn1, m._conv_head]),
    ).map(params)


def create_model(
    model_arq, n_out, model=None, pretrained=True, n_in=1, ema=False, bn_final=False
):
    if model is None:
        if type(model_arq) is str and model_arq.startswith(&#34;efficientnet&#34;):
            model = EfficientNet.from_pretrained(
                model_arq, num_classes=n_out, include_top=True, in_channels=n_in
            )
        else:
            model = create_cnn_model(
                model_arq,
                n_out=n_out,
                cut=None,
                pretrained=pretrained,
                n_in=n_in,
                bn_final=bn_final,
            )

    if torch.cuda.is_available():
        model = model.cuda()

    if ema:
        for param in model.parameters():
            param.detach_()

    return model


# TODO: This creates issue with a huge difference between training and validation
# seems like the logits are one or two order of magnitude higher during validation
class EMAModel(Callback):
    &#34;&#34;&#34;Evaluate model during validation with a EMA model
    Based on https://raw.githubusercontent.com/valencebond/FixMatch_pytorch/master/models/ema.py
    &#34;&#34;&#34;

    def __init__(self, alpha=0.999):
        self.alpha = alpha

    def after_create(self):
        self.shadow = self.get_model_state()
        self.backup = {}
        self.param_keys = [k for k, _ in self.model.named_parameters()]

    def after_batch(self):
        if not self.training:
            return
        self.update_params()

    def before_validate(self):
        self.apply_shadow()

    def after_validate(self):
        self.restore()

    def update_params(self):
        decay = self.alpha
        state = self.model.state_dict()  # current params
        for name in self.param_keys:
            self.shadow[name].copy_(
                decay * self.shadow[name] + (1 - decay) * state[name]
            )

    def apply_shadow(self):
        self.backup = self.get_model_state()
        self.model.load_state_dict(self.shadow)

    def restore(self):
        self.model.load_state_dict(self.backup)

    def get_model_state(self):
        return {k: v.clone().detach() for k, v in self.model.state_dict().items()}


def get_training_model(run_params, loss_params, train_df, n_in=1, model_self_sup=None):
    classes = train_df[&#34;Target&#34;].unique()
    n_out = len(classes)

    if run_params[&#34;USE_SAVED_MODEL&#34;]:
        body = create_model(
            run_params[&#34;MODEL&#34;], n_out, pretrained=True, n_in=n_in, bn_final=True
        )

        load_model(
            file=run_params[&#34;PRETRAINED_MODEL_SAVE_NAME&#34;],
            model=body,
            opt=None,
            with_opt=False,
            device=torch.cuda.current_device(),
            strict=False,
        )
        body = body[0]

        nf = num_features_model(nn.Sequential(*body.children())) * 2
        head = create_head(
            nf, n_out, concat_pool=True, bn_final=True, ps=run_params[&#34;HEAD_DROPOUT_P&#34;]
        )

        model = nn.Sequential(body, head)
        apply_init(model[1], nn.init.kaiming_normal_)

    elif run_params[&#34;SELF_SUPERVISED&#34;]:
        if model_self_sup is None:
            raise ValueError(&#34;No Self Supervised model provided&#34;)

        concat_pool = True
        for i, layer_block in enumerate(model_self_sup.children()):
            if i == 1:
                for layer in layer_block.children():
                    for j, layer_ in enumerate(layer.children()):
                        if j == 3:
                            nf = layer_.out_features
        # nf = num_features_model(nn.Sequential(*model_self_sup.children())) * (2 if concat_pool else 1)
        # head = create_head(nf, n_out, lin_ftrs=[512], ps=0.5, concat_pool=concat_pool, bn_final=True)

        # Seems there is somekind of issue and nf only can be 2048
        nf = 2048
        layers = [
            nn.Dropout(p=run_params[&#34;HEAD_DROPOUT_P&#34;]),
            nn.Linear(nf, n_out),
            nn.BatchNorm1d(n_out, momentum=0.01),
        ]
        head = nn.Sequential(*layers)
        model = nn.Sequential(model_self_sup, head)
    else:
        model = create_model(
            run_params[&#34;MODEL&#34;], n_out, pretrained=True, n_in=n_in, bn_final=True
        )

    # TODO: Should be corrected depending on the ALL_LABELS_IN_BATCH or WEIGTHED_SAMPLER?
    # Initialize last BatchNorm bias with values reflecting the current probabilities with Softmax
    with torch.no_grad():
        try:
            vals = torch.as_tensor(
                [
                    np.log(p)
                    for p in train_df[&#34;Target&#34;].value_counts(normalize=True).values
                ]
            )
            for name, param in model[-1][-1].named_parameters():
                if &#34;bias&#34; in name:
                    param.copy_(vals)
        except TypeError:
            model._fc.bias.copy_(vals)

    if torch.cuda.is_available():
        model = model.cuda()

    if run_params[&#34;SSL&#34;]:
        if run_params[&#34;SSL&#34;] == run_params[&#34;SSL_MIX_MATCH&#34;]:
            loss_params[&#34;model&#34;] = model

        # EMAModel needs to be fixed before being used again
        # cbs.append(EMAModel(alpha=run_params[&#39;EMA_DECAY&#39;]))

    # Get splitter for model param groups
    meta = model_meta.get(run_params[&#34;MODEL&#34;], {&#34;cut&#34;: -1, &#34;split&#34;: default_split})
    splitter = (
        efficientNet_split
        if type(run_params[&#34;MODEL&#34;]) is str
        and run_params[&#34;MODEL&#34;].startswith(&#34;efficientnet&#34;)
        else meta[&#34;split&#34;]
    )

    return model, splitter</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="radiology_ai.train.models.create_model"><code class="name flex">
<span>def <span class="ident">create_model</span></span>(<span>model_arq, n_out, model=None, pretrained=True, n_in=1, ema=False, bn_final=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L26-L51" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def create_model(
    model_arq, n_out, model=None, pretrained=True, n_in=1, ema=False, bn_final=False
):
    if model is None:
        if type(model_arq) is str and model_arq.startswith(&#34;efficientnet&#34;):
            model = EfficientNet.from_pretrained(
                model_arq, num_classes=n_out, include_top=True, in_channels=n_in
            )
        else:
            model = create_cnn_model(
                model_arq,
                n_out=n_out,
                cut=None,
                pretrained=pretrained,
                n_in=n_in,
                bn_final=bn_final,
            )

    if torch.cuda.is_available():
        model = model.cuda()

    if ema:
        for param in model.parameters():
            param.detach_()

    return model</code></pre>
</details>
</dd>
<dt id="radiology_ai.train.models.efficientNet_split"><code class="name flex">
<span>def <span class="ident">efficientNet_split</span></span>(<span>m)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L19-L23" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def efficientNet_split(m):
    return L(
        torch.nn.ModuleList([m._swish, m._bn0, m._conv_stem, m._blocks]),
        torch.nn.ModuleList([m._swish, m._bn1, m._conv_head]),
    ).map(params)</code></pre>
</details>
</dd>
<dt id="radiology_ai.train.models.get_training_model"><code class="name flex">
<span>def <span class="ident">get_training_model</span></span>(<span>run_params, loss_params, train_df, n_in=1, model_self_sup=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L99-L189" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_training_model(run_params, loss_params, train_df, n_in=1, model_self_sup=None):
    classes = train_df[&#34;Target&#34;].unique()
    n_out = len(classes)

    if run_params[&#34;USE_SAVED_MODEL&#34;]:
        body = create_model(
            run_params[&#34;MODEL&#34;], n_out, pretrained=True, n_in=n_in, bn_final=True
        )

        load_model(
            file=run_params[&#34;PRETRAINED_MODEL_SAVE_NAME&#34;],
            model=body,
            opt=None,
            with_opt=False,
            device=torch.cuda.current_device(),
            strict=False,
        )
        body = body[0]

        nf = num_features_model(nn.Sequential(*body.children())) * 2
        head = create_head(
            nf, n_out, concat_pool=True, bn_final=True, ps=run_params[&#34;HEAD_DROPOUT_P&#34;]
        )

        model = nn.Sequential(body, head)
        apply_init(model[1], nn.init.kaiming_normal_)

    elif run_params[&#34;SELF_SUPERVISED&#34;]:
        if model_self_sup is None:
            raise ValueError(&#34;No Self Supervised model provided&#34;)

        concat_pool = True
        for i, layer_block in enumerate(model_self_sup.children()):
            if i == 1:
                for layer in layer_block.children():
                    for j, layer_ in enumerate(layer.children()):
                        if j == 3:
                            nf = layer_.out_features
        # nf = num_features_model(nn.Sequential(*model_self_sup.children())) * (2 if concat_pool else 1)
        # head = create_head(nf, n_out, lin_ftrs=[512], ps=0.5, concat_pool=concat_pool, bn_final=True)

        # Seems there is somekind of issue and nf only can be 2048
        nf = 2048
        layers = [
            nn.Dropout(p=run_params[&#34;HEAD_DROPOUT_P&#34;]),
            nn.Linear(nf, n_out),
            nn.BatchNorm1d(n_out, momentum=0.01),
        ]
        head = nn.Sequential(*layers)
        model = nn.Sequential(model_self_sup, head)
    else:
        model = create_model(
            run_params[&#34;MODEL&#34;], n_out, pretrained=True, n_in=n_in, bn_final=True
        )

    # TODO: Should be corrected depending on the ALL_LABELS_IN_BATCH or WEIGTHED_SAMPLER?
    # Initialize last BatchNorm bias with values reflecting the current probabilities with Softmax
    with torch.no_grad():
        try:
            vals = torch.as_tensor(
                [
                    np.log(p)
                    for p in train_df[&#34;Target&#34;].value_counts(normalize=True).values
                ]
            )
            for name, param in model[-1][-1].named_parameters():
                if &#34;bias&#34; in name:
                    param.copy_(vals)
        except TypeError:
            model._fc.bias.copy_(vals)

    if torch.cuda.is_available():
        model = model.cuda()

    if run_params[&#34;SSL&#34;]:
        if run_params[&#34;SSL&#34;] == run_params[&#34;SSL_MIX_MATCH&#34;]:
            loss_params[&#34;model&#34;] = model

        # EMAModel needs to be fixed before being used again
        # cbs.append(EMAModel(alpha=run_params[&#39;EMA_DECAY&#39;]))

    # Get splitter for model param groups
    meta = model_meta.get(run_params[&#34;MODEL&#34;], {&#34;cut&#34;: -1, &#34;split&#34;: default_split})
    splitter = (
        efficientNet_split
        if type(run_params[&#34;MODEL&#34;]) is str
        and run_params[&#34;MODEL&#34;].startswith(&#34;efficientnet&#34;)
        else meta[&#34;split&#34;]
    )

    return model, splitter</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="radiology_ai.train.models.EMAModel"><code class="flex name class">
<span>class <span class="ident">EMAModel</span></span>
<span>(</span><span>alpha=0.999)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate model during validation with a EMA model
Based on <a href="https://raw.githubusercontent.com/valencebond/FixMatch_pytorch/master/models/ema.py">https://raw.githubusercontent.com/valencebond/FixMatch_pytorch/master/models/ema.py</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L56-L96" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class EMAModel(Callback):
    &#34;&#34;&#34;Evaluate model during validation with a EMA model
    Based on https://raw.githubusercontent.com/valencebond/FixMatch_pytorch/master/models/ema.py
    &#34;&#34;&#34;

    def __init__(self, alpha=0.999):
        self.alpha = alpha

    def after_create(self):
        self.shadow = self.get_model_state()
        self.backup = {}
        self.param_keys = [k for k, _ in self.model.named_parameters()]

    def after_batch(self):
        if not self.training:
            return
        self.update_params()

    def before_validate(self):
        self.apply_shadow()

    def after_validate(self):
        self.restore()

    def update_params(self):
        decay = self.alpha
        state = self.model.state_dict()  # current params
        for name in self.param_keys:
            self.shadow[name].copy_(
                decay * self.shadow[name] + (1 - decay) * state[name]
            )

    def apply_shadow(self):
        self.backup = self.get_model_state()
        self.model.load_state_dict(self.shadow)

    def restore(self):
        self.model.load_state_dict(self.backup)

    def get_model_state(self):
        return {k: v.clone().detach() for k, v in self.model.state_dict().items()}</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>fastai.callback.core.Callback</li>
<li>fastcore.basics.Stateful</li>
<li>fastcore.basics.GetAttr</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="radiology_ai.train.models.EMAModel.after_batch"><code class="name flex">
<span>def <span class="ident">after_batch</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L69-L72" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def after_batch(self):
    if not self.training:
        return
    self.update_params()</code></pre>
</details>
</dd>
<dt id="radiology_ai.train.models.EMAModel.after_create"><code class="name flex">
<span>def <span class="ident">after_create</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L64-L67" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def after_create(self):
    self.shadow = self.get_model_state()
    self.backup = {}
    self.param_keys = [k for k, _ in self.model.named_parameters()]</code></pre>
</details>
</dd>
<dt id="radiology_ai.train.models.EMAModel.after_validate"><code class="name flex">
<span>def <span class="ident">after_validate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L77-L78" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def after_validate(self):
    self.restore()</code></pre>
</details>
</dd>
<dt id="radiology_ai.train.models.EMAModel.apply_shadow"><code class="name flex">
<span>def <span class="ident">apply_shadow</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L88-L90" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def apply_shadow(self):
    self.backup = self.get_model_state()
    self.model.load_state_dict(self.shadow)</code></pre>
</details>
</dd>
<dt id="radiology_ai.train.models.EMAModel.before_validate"><code class="name flex">
<span>def <span class="ident">before_validate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L74-L75" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def before_validate(self):
    self.apply_shadow()</code></pre>
</details>
</dd>
<dt id="radiology_ai.train.models.EMAModel.get_model_state"><code class="name flex">
<span>def <span class="ident">get_model_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L95-L96" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_model_state(self):
    return {k: v.clone().detach() for k, v in self.model.state_dict().items()}</code></pre>
</details>
</dd>
<dt id="radiology_ai.train.models.EMAModel.restore"><code class="name flex">
<span>def <span class="ident">restore</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L92-L93" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def restore(self):
    self.model.load_state_dict(self.backup)</code></pre>
</details>
</dd>
<dt id="radiology_ai.train.models.EMAModel.update_params"><code class="name flex">
<span>def <span class="ident">update_params</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/lluissalord/radiology_ai/blob/954877ea22203b4d69aaebf53cb0f86bffd25a13/train\models.py#L80-L86" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def update_params(self):
    decay = self.alpha
    state = self.model.state_dict()  # current params
    for name in self.param_keys:
        self.shadow[name].copy_(
            decay * self.shadow[name] + (1 - decay) * state[name]
        )</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="gcse-search" style="height: 70px"
data-as_oq="inurl:github.com/lluissalord/radiology_ai site:radiology_ai.github.io site:radiology_ai.website"
data-gaCategoryParameter="radiology_ai.train.models">
</div>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="radiology_ai.train" href="index.html">radiology_ai.train</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="radiology_ai.train.models.create_model" href="#radiology_ai.train.models.create_model">create_model</a></code></li>
<li><code><a title="radiology_ai.train.models.efficientNet_split" href="#radiology_ai.train.models.efficientNet_split">efficientNet_split</a></code></li>
<li><code><a title="radiology_ai.train.models.get_training_model" href="#radiology_ai.train.models.get_training_model">get_training_model</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="radiology_ai.train.models.EMAModel" href="#radiology_ai.train.models.EMAModel">EMAModel</a></code></h4>
<ul class="two-column">
<li><code><a title="radiology_ai.train.models.EMAModel.after_batch" href="#radiology_ai.train.models.EMAModel.after_batch">after_batch</a></code></li>
<li><code><a title="radiology_ai.train.models.EMAModel.after_create" href="#radiology_ai.train.models.EMAModel.after_create">after_create</a></code></li>
<li><code><a title="radiology_ai.train.models.EMAModel.after_validate" href="#radiology_ai.train.models.EMAModel.after_validate">after_validate</a></code></li>
<li><code><a title="radiology_ai.train.models.EMAModel.apply_shadow" href="#radiology_ai.train.models.EMAModel.apply_shadow">apply_shadow</a></code></li>
<li><code><a title="radiology_ai.train.models.EMAModel.before_validate" href="#radiology_ai.train.models.EMAModel.before_validate">before_validate</a></code></li>
<li><code><a title="radiology_ai.train.models.EMAModel.get_model_state" href="#radiology_ai.train.models.EMAModel.get_model_state">get_model_state</a></code></li>
<li><code><a title="radiology_ai.train.models.EMAModel.restore" href="#radiology_ai.train.models.EMAModel.restore">restore</a></code></li>
<li><code><a title="radiology_ai.train.models.EMAModel.update_params" href="#radiology_ai.train.models.EMAModel.update_params">update_params</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>