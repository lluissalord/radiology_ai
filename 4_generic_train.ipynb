{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "8_self_supervised.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python37864bitradiologyaiconda1d6e040f57e346eb9ba4a0a95c0ad7a6",
      "display_name": "Python 3.7.8 64-bit ('radiology_ai': conda)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11-final"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de1358842c564ad2b3b6f066ce9d19de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03ba3e4306ef4d6c8e21d7c4b8c15989",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b345f8ec03bd495a8cd4bfc5ab748943",
              "IPY_MODEL_cffe60df10d144d9abeb3fe65805291a",
              "IPY_MODEL_18179a293976453abff08d53c37c9d4f"
            ]
          }
        },
        "03ba3e4306ef4d6c8e21d7c4b8c15989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b345f8ec03bd495a8cd4bfc5ab748943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b5a4b198a39c420aa71742efce970552",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Label files: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71a42c0ee64447bc93294a5e009679cc"
          }
        },
        "cffe60df10d144d9abeb3fe65805291a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0c1422bd9cb2431a84a8304fb463c020",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 340,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 340,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_647d4c26ae8d4618b0a494fd23c1871b"
          }
        },
        "18179a293976453abff08d53c37c9d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d7cc2af005544a8a0e8e3654c2c0acc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 340/340 [08:32&lt;00:00,  1.51s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_341810cae390407b9da0ede7aa030423"
          }
        },
        "b5a4b198a39c420aa71742efce970552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71a42c0ee64447bc93294a5e009679cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c1422bd9cb2431a84a8304fb463c020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "647d4c26ae8d4618b0a494fd23c1871b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d7cc2af005544a8a0e8e3654c2c0acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "341810cae390407b9da0ede7aa030423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77fcb5d225ca405183180d8460294c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_289340db08744e62b0d8800f8cd6ccb4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f21eff4e6de84ea9ad545f2e2466dd03",
              "IPY_MODEL_009d4a9d4fd249df809f84b9571c376e",
              "IPY_MODEL_ce9daa7195884b7f89415c7f395456c1"
            ]
          }
        },
        "289340db08744e62b0d8800f8cd6ccb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f21eff4e6de84ea9ad545f2e2466dd03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6a7215a40bf4cf190221f5bca0368c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_451be98dd6d245a1b3473082307ec2a0"
          }
        },
        "009d4a9d4fd249df809f84b9571c376e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f2d2fcac8c2489bbfa1d128f0a27e0c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5017600,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5017600,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de2f2dd9221c46b3a7bb6ff699bd7dc3"
          }
        },
        "ce9daa7195884b7f89415c7f395456c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b647797d7604c228fb130375129100d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.79M/4.79M [00:03&lt;00:00, 1.47MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec490770badc47ae99c2101124381e21"
          }
        },
        "c6a7215a40bf4cf190221f5bca0368c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "451be98dd6d245a1b3473082307ec2a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f2d2fcac8c2489bbfa1d128f0a27e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de2f2dd9221c46b3a7bb6ff699bd7dc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b647797d7604c228fb130375129100d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec490770badc47ae99c2101124381e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNVBYRs20LuP",
        "outputId": "7cbf6c9b-8683-46b5-eb50-44f6fe0b3623",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Define if we are on Colab and mount drive { display-mode: \"form\" }\n",
        "run_params = {}\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  run_params['IN_COLAB'] = True\n",
        "except:\n",
        "  run_params['IN_COLAB'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTVYFJLi0LuR",
        "outputId": "c0452fef-cbed-4a92-c074-42f61752a97b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title (COLAB ONLY) Clone GitHub repo { display-mode: \"form\" }\n",
        "\n",
        "if run_params['IN_COLAB']:\n",
        "  !git clone https://github.com/lluissalord/radiology_ai.git\n",
        "\n",
        "  %cd radiology_ai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI74zRR30LuR",
        "outputId": "63056837-079f-4fbb-ef69-e0bed3c0d0fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Setup environment and Colab general variables { display-mode: \"form\" }\n",
        "# %%capture\n",
        "%run colab_setup.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSiXwErZ0LuR"
      },
      "source": [
        "#@title Move images from Drive to temporary folder here to be able to train models { display-mode: \"form\" }\n",
        "# %%capture\n",
        "%run move_raw_preprocess.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hg2rdo10LuS"
      },
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from fastai.basics import *\n",
        "from fastai.callback.all import *\n",
        "from fastai.data.block import *\n",
        "from fastai.data.transforms import *\n",
        "from fastai.vision import models\n",
        "from fastai.vision.learner import *\n",
        "from fastai.vision.augment import *\n",
        "from fastai.vision.core import PILImageBW, PILImage\n",
        "from fastai.vision.data import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHP8hO5n0LuS"
      },
      "source": [
        "run_params['SELF_SUPERVISED'] = True\n",
        "run_params['SELF_SUPERVISED_TRAIN'] = True\n",
        "\n",
        "if run_params['SELF_SUPERVISED']:\n",
        "    import pl_bolts\n",
        "    from pl_bolts.models.self_supervised import SimCLR\n",
        "    from pl_bolts.models.self_supervised.simclr import SimCLRTrainDataTransform, SimCLREvalDataTransform\n",
        "    from pytorch_lightning import Trainer\n",
        "    from pytorch_lightning.loggers import TensorBoardLogger\n",
        "    from pytorch_lightning.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0Xy_3As0LuS"
      },
      "source": [
        "from preprocessing.transforms import *\n",
        "# from preprocessing.dicom import *\n",
        "from preprocessing.misc import *\n",
        "\n",
        "from utils.models import *\n",
        "from utils.organize import *\n",
        "from utils.misc import *\n",
        "from utils.data import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfeOxI7n0LuS"
      },
      "source": [
        "run_params['SSL_MIX_MATCH'] = 'MixMatch'\n",
        "run_params['SSL_FIX_MATCH'] = 'FixMatch'\n",
        "\n",
        "run_params['SSL'] = run_params['SSL_FIX_MATCH']\n",
        "# run_params['SSL'] = None\n",
        "\n",
        "if run_params['SSL'] == run_params['SSL_FIX_MATCH']:\n",
        "    from semisupervised.fixmatch.losses import FixMatchLoss as SSLLoss\n",
        "    from semisupervised.fixmatch.callback import FixMatchCallback as SSLCallback\n",
        "elif run_params['SSL'] == run_params['SSL_MIX_MATCH']:\n",
        "    from semisupervised.mixmatch.losses import MixMatchLoss as SSLLoss\n",
        "    from semisupervised.mixmatch.callback import MixMatchCallback as SSLCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxB821yt0LuT"
      },
      "source": [
        "run_params['TEST_SIZE'] = 0.15\n",
        "run_params['VALID_SIZE'] = 0.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjzPt9Ea0LuT"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "run_params['HIST_CLIPPING'] = True\n",
        "run_params['HIST_CLIPPING_CUT_MIN'] = 5.\n",
        "run_params['HIST_CLIPPING_CUT_MAX'] = 99.\n",
        "\n",
        "run_params['KNEE_LOCALIZER'] = True\n",
        "run_params['CLAHE_SCALED'] = True\n",
        "run_params['HIST_SCALED'] = False\n",
        "run_params['HIST_SCALED_SELF'] = True\n",
        "\n",
        "run_params['BINARY_CLASSIFICATION'] = True\n",
        "\n",
        "run_params['CLASS_WEIGHT'] = True\n",
        "run_params['WEIGTHED_SAMPLER'] = False\n",
        "run_params['ALL_LABELS_IN_BATCH'] = True\n",
        "run_params['MIN_SAMPLES_PER_LABEL'] = 1\n",
        "\n",
        "run_params['LR'] = 0.0005\n",
        "run_params['GRAD_CLIP_VAL'] = 1 # None\n",
        "\n",
        "run_params['RESIZE'] = 384\n",
        "run_params['RANDOM_RESIZE_CROP'] = 224\n",
        "run_params['RANDOM_MIN_SCALE'] = 0.5\n",
        "\n",
        "run_params['SELF_SUPERVISED_BATCH_SIZE'] = 64\n",
        "\n",
        "if run_params['SSL']:\n",
        "    if run_params['SSL'] == run_params['SSL_FIX_MATCH']:\n",
        "        run_params['BATCH_SIZE'] = 8\n",
        "        run_params['MOMENTUM'] = 0.9\n",
        "        run_params['WD'] = 0.0005\n",
        "        run_params['LAMBDA_U'] = 1\n",
        "        run_params['MU'] = 5\n",
        "        run_params['LABEL_THRESHOLD'] = 0.95\n",
        "\n",
        "        cb_params = {}\n",
        "\n",
        "        loss_params = {\n",
        "            'bs': run_params['BATCH_SIZE'],\n",
        "            'mu': run_params['MU'],\n",
        "            'lambda_u': run_params['LAMBDA_U'],\n",
        "            'label_threshold': run_params['LABEL_THRESHOLD']\n",
        "        }\n",
        "    elif run_params['SSL'] == run_params['SSL_MIX_MATCH']:\n",
        "        run_params['BATCH_SIZE'] = 16\n",
        "        run_params['LAMBDA_U'] = 75\n",
        "        run_params['T'] = 0.5\n",
        "        run_params['ALPHA'] = 0.75\n",
        "\n",
        "        cb_params = {\n",
        "            'T': run_params['T']\n",
        "        }\n",
        "\n",
        "        loss_params = {\n",
        "            'bs': run_params['BATCH_SIZE'],\n",
        "            'lambda_u': run_params['LAMBDA_U'],\n",
        "        }\n",
        "\n",
        "    loss_params['use_SCL'] = True\n",
        "    loss_params['beta'] = 0.5\n",
        "\n",
        "    run_params['EMA_DECAY'] = 0.999\n",
        "else:\n",
        "    run_params['BATCH_SIZE'] = 32\n",
        "\n",
        "\n",
        "run_params['USE_SAVED_MODEL'] = True\n",
        "run_params['SAVE_MODEL'] = False\n",
        "\n",
        "run_params['MODEL'] = models.resnet18\n",
        "run_params['MODEL'] = models.squeezenet1_0\n",
        "# MODEL = 'efficientnet-b0'\n",
        "run_params['MODEL_VERSION'] = 0\n",
        "run_params['MODEL_DESCRIPTION'] = f'{\"SSL_\" if run_params[\"SSL\"] else \"\"}{\"SELFSUP_\" if run_params[\"SELF_SUPERVISED\"] else \"\"}sz{min(run_params[\"RESIZE\"], run_params[\"RANDOM_RESIZE_CROP\"])}'\n",
        "run_params['MODEL_SAVE_NAME'] = f'{run_params[\"MODEL\"].__name__}_{run_params[\"MODEL_DESCRIPTION\"]}_v{run_params[\"MODEL_VERSION\"]}.pkl'\n",
        "run_params['MODEL_SAVE_PATH'] = os.path.join(run_params['MODELS_FOLDER'], run_params['MODEL_SAVE_NAME'])\n",
        "\n",
        "run_params['PRETRAINED_MODEL_SAVE_NAME'] = 'resnet18_v0.pkl'\n",
        "run_params['PRETRAINED_MODEL_SAVE_NAME'] = os.path.join(run_params['MODELS_FOLDER'], run_params['PRETRAINED_MODEL_SAVE_NAME'])\n",
        "if run_params['USE_SAVED_MODEL'] and not os.path.exists(run_params['PRETRAINED_MODEL_SAVE_NAME']):\n",
        "    print(f'Not using pretrained model as there is no model on: {run_params[\"PRETRAINED_MODEL_SAVE_NAME\"]}')\n",
        "    run_params['USE_SAVED_MODEL'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y407niUQ0LuT",
        "outputId": "b074b7c2-62cf-4e81-d215-c4c272a7da7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "run_params['SEED'] = 42\n",
        "\n",
        "seed_everything(run_params['SEED'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9ulgPZD0LuU"
      },
      "source": [
        "# Transformations\n",
        "\n",
        "item_tfms = []\n",
        "\n",
        "if run_params['HIST_CLIPPING']:\n",
        "    item_tfms.append(XRayPreprocess(PIL_cls=PILImageBW, cut_min=run_params['HIST_CLIPPING_CUT_MIN'], cut_max=run_params['HIST_CLIPPING_CUT_MAX'], np_input=len(item_tfms) > 0, np_output=True))\n",
        "\n",
        "if run_params['KNEE_LOCALIZER']:\n",
        "    item_tfms.append(KneeLocalizer(run_params['KNEE_SVM_MODEL_PATH'], PIL_cls=PILImageBW, resize=run_params['RESIZE'], np_input=len(item_tfms) > 0, np_output=True))\n",
        "else:\n",
        "    item_tfms.append(Resize(run_params['RESIZE'], method=ResizeMethod.Pad, pad_mode=PadMode.Zeros))\n",
        "\n",
        "# item_tfms.append(RandomResizedCrop(RANDOM_RESIZE_CROP))\n",
        "\n",
        "label_transform = [\n",
        "    # Flip(),\n",
        "    *aug_transforms(\n",
        "        pad_mode=PadMode.Zeros,\n",
        "    ),\n",
        "    RandomResizedCropGPU(run_params['RANDOM_RESIZE_CROP'], min_scale=run_params['RANDOM_MIN_SCALE']),\n",
        "    Normalize()\n",
        "]\n",
        "\n",
        "unlabel_batch_tfms = [None]\n",
        "if run_params['SSL'] == run_params['SSL_FIX_MATCH']:\n",
        "\n",
        "    weak_transform = [\n",
        "        RandomResizedCropGPU(run_params['RANDOM_RESIZE_CROP']),\n",
        "        Flip(),\n",
        "        Normalize()\n",
        "    ]\n",
        "    unlabel_batch_tfms.append(weak_transform)\n",
        "\n",
        "    strong_transform = [\n",
        "        RandomResizedCropGPU(run_params['RANDOM_RESIZE_CROP']),\n",
        "        Flip(),\n",
        "        Rotate(90),\n",
        "        Brightness(),\n",
        "        Contrast(),\n",
        "        RandomErasing(),\n",
        "        Normalize()\n",
        "    ]\n",
        "    unlabel_batch_tfms.append(strong_transform)\n",
        "\n",
        "elif run_params['SSL'] == run_params['SSL_MIX_MATCH']:\n",
        "\n",
        "    unlabel_transform = [\n",
        "        RandomResizedCropGPU(run_params['RANDOM_RESIZE_CROP']),\n",
        "        Flip(),\n",
        "        Rotate(180),\n",
        "        Brightness(),\n",
        "        Contrast(),\n",
        "        Normalize()\n",
        "    ]\n",
        "    unlabel_batch_tfms.append(unlabel_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItBoJQEZ0LuU"
      },
      "source": [
        "# Callbacks\n",
        "from fastai.callback.tensorboard import TensorBoardCallback\n",
        "from fastai.callback import *\n",
        "\n",
        "cbs = None\n",
        "cbs = [\n",
        "    TensorBoardCallback(projector=True),\n",
        "]\n",
        "if not run_params['SSL']:\n",
        "    cbs = [\n",
        "        MixUp()\n",
        "    ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyoeBxLT0LuU",
        "outputId": "4f7a1558-936b-437e-ebdd-b2dae5c4a9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "de1358842c564ad2b3b6f066ce9d19de",
            "03ba3e4306ef4d6c8e21d7c4b8c15989",
            "b345f8ec03bd495a8cd4bfc5ab748943",
            "cffe60df10d144d9abeb3fe65805291a",
            "18179a293976453abff08d53c37c9d4f",
            "b5a4b198a39c420aa71742efce970552",
            "71a42c0ee64447bc93294a5e009679cc",
            "0c1422bd9cb2431a84a8304fb463c020",
            "647d4c26ae8d4618b0a494fd23c1871b",
            "0d7cc2af005544a8a0e8e3654c2c0acc",
            "341810cae390407b9da0ede7aa030423"
          ]
        }
      },
      "source": [
        "if run_params['IN_COLAB']:\n",
        "  df = concat_templates(run_params['ORGANIZE_FOLDER'], excel=True)\n",
        "  df.to_excel(\n",
        "      os.path.join(run_params['PATH_PREFIX'], 'all.xlsx'),\n",
        "      index=False\n",
        "  )\n",
        "else:\n",
        "  df = pd.read_excel(os.path.join(run_params['PATH_PREFIX'], 'all.xlsx'), dtype={'ID':'string','Target':'string'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl1x6cE20LuU",
        "outputId": "cfa0f7be-d1e4-4f1a-cc88-1aa67f58896c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Data\n",
        "\n",
        "# Load DataFrame of relation between Original Filename and ID (IMG_XXX)\n",
        "relation_df = pd.read_csv(os.path.join(run_params['PATH_PREFIX'], 'relation.csv'))\n",
        "relation_df = relation_df.set_index('Filename')\n",
        "\n",
        "# Merge data to be able to load directly from preprocessed PNG file\n",
        "final_df = df.set_index('ID').merge(relation_df, left_index=True, right_index=True)\n",
        "final_df['ID'] = final_df.index.values\n",
        "final_df = final_df.reset_index(drop=True)\n",
        "final_df['Raw_preprocess'] = final_df['Original_Filename'].apply(lambda filename: os.path.join(run_params['RAW_PREPROCESS_FOLDER'], filename + '.png'))\n",
        "\n",
        "# Load DataFrame containing labels of OOS classifier ('ap', 'other')\n",
        "metadata_labels_path = os.path.join(run_params['PATH_PREFIX'], 'metadata_labels.csv')\n",
        "metadata_labels = pd.read_csv(metadata_labels_path)\n",
        "metadata_labels = metadata_labels.set_index('Path')\n",
        "\n",
        "# Merge all the data we have with the labelling in order to split correctly according to OOS classifier\n",
        "unlabel_all_df = metadata_labels.merge(final_df.set_index('Raw_preprocess'), how='left', left_index=True, right_index=True)\n",
        "unlabel_all_df = unlabel_all_df[unlabel_all_df.Target.isnull()]\n",
        "unlabel_all_df['Raw_preprocess'] = unlabel_all_df.index.values\n",
        "\n",
        "# Define which column to use as the prediction\n",
        "if 'Final_pred' in unlabel_all_df.columns:\n",
        "    pred_col = 'Final_pred'\n",
        "else:\n",
        "    pred_col = 'Pred'\n",
        "\n",
        "# Conditions for AP radiographies on unlabel data\n",
        "ap_match = (unlabel_all_df[pred_col] == 'ap') & (unlabel_all_df.Incorrect_image.isnull())\n",
        "\n",
        "# Split between label_df (labelled data), `unlabel_df` (containing only AP) and `unlabel_other_df` (with the rest of unlabel data)\n",
        "label_df = final_df[final_df['Target'].notnull()].reset_index(drop=True)\n",
        "if run_params['BINARY_CLASSIFICATION']:\n",
        "  label_df['Target'] = (label_df['Target'] != '0').astype(int).astype('string')\n",
        "unlabel_df = unlabel_all_df[ap_match].reset_index(drop=True)\n",
        "unlabel_other_df = unlabel_all_df[~ap_match].reset_index(drop=True)\n",
        "\n",
        "print(f'Currently {len(label_df.index)} data have been labelled')\n",
        "print(f'Remaining {len(unlabel_df.index)} data to be labelled')\n",
        "print(f'Discarded {len(unlabel_other_df.index)} data')\n",
        "\n",
        "# Split between train, valid and test\n",
        "try:\n",
        "  train_df, test_df = train_test_split(label_df, test_size=run_params['TEST_SIZE'], shuffle=True, stratify=label_df['Target'], random_state=run_params['SEED'])\n",
        "except ValueError:\n",
        "  train_df, test_df = train_test_split(label_df, test_size=run_params['TEST_SIZE'], shuffle=True, random_state=run_params['SEED'])\n",
        "\n",
        "try:\n",
        "  train_df, val_df = train_test_split(train_df, test_size=run_params['VALID_SIZE']/(1-run_params['TEST_SIZE']), shuffle=True, stratify=train_df['Target'], random_state=run_params['SEED'])\n",
        "except ValueError:\n",
        "  train_df, val_df = train_test_split(train_df, test_size=run_params['VALID_SIZE']/(1-run_params['TEST_SIZE']), shuffle=True, random_state=run_params['SEED'])\n",
        "\n",
        "label_df.loc[train_df.index, 'Dataset'] = 'train'\n",
        "label_df.loc[val_df.index, 'Dataset'] = 'valid'\n",
        "label_df.loc[test_df.index, 'Dataset'] = 'test'\n",
        "\n",
        "print('\\nSplit of labelled data is:')\n",
        "display(label_df['Dataset'].value_counts())\n",
        "\n",
        "sort_dataset = {'train': 0, 'valid': 1, 'test': 2}\n",
        "label_df = label_df.sort_values('Dataset', key=lambda x: x.map(sort_dataset)).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkYDWIen0LuU"
      },
      "source": [
        "# Histogram scaling DICOM on the fly\n",
        "\n",
        "if run_params['CLAHE_SCALED']:\n",
        "    item_tfms.append(CLAHE_Transform(PIL_cls=PILImageBW, grayscale=not run_params['SELF_SUPERVISED'], np_input=len(item_tfms) > 0, np_output=False))\n",
        "elif run_params['HIST_SCALED']:\n",
        "    if run_params['HIST_SCALED_SELF']:\n",
        "        bins = None\n",
        "    else:\n",
        "        # bins = init_bins(fnames=L(list(final_df['Original'].values)), n_samples=100)\n",
        "        all_valid_raw_preprocess = pd.concat([pd.Series(unlabel_all_df.index), label_df['Raw_preprocess']])\n",
        "        bins = init_bins(fnames=L(list(all_valid_raw_preprocess.values)), n_samples=100, isDCM=False)\n",
        "    # item_tfms.append(HistScaled(bins))\n",
        "    item_tfms.append(HistScaled_all(bins))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if run_params['IN_COLAB']:\n",
        "  # Load the TensorBoard notebook extension\n",
        "  %load_ext tensorboard\n",
        "\n",
        "  %tensorboard --logdir {'\"' + os.path.join(run_params['PATH_PREFIX'] , 'tb_logs') + '\"'}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMGNEOsw0LuW"
      },
      "source": [
        "if run_params['SELF_SUPERVISED']:\n",
        "\n",
        "    checkpoints_dir = os.path.join(run_params['PATH_PREFIX'] , 'checkpoints')\n",
        "    checkpoint_resume = os.path.join(checkpoints_dir , run_params['MODEL_SAVE_NAME']+'.ckpt')\n",
        "\n",
        "    dataset = SelfSupervisedDataset(final_df, validation = False, transform = SimCLRTrainDataTransform(min(run_params['RESIZE'], run_params['RANDOM_RESIZE_CROP'])), prefix=run_params['RAW_PREPROCESS_FOLDER']+'/')\n",
        "    val_dataset = SelfSupervisedDataset(final_df, validation = True, transform = SimCLREvalDataTransform(min(run_params['RESIZE'], run_params['RANDOM_RESIZE_CROP'])), prefix=run_params['RAW_PREPROCESS_FOLDER']+'/')\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(dataset,\n",
        "                                              batch_size=run_params['SELF_SUPERVISED_BATCH_SIZE'],\n",
        "                                              num_workers=0)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                              batch_size=run_params['SELF_SUPERVISED_BATCH_SIZE'],\n",
        "                                              num_workers=0)\n",
        "    num_samples = len(dataset)\n",
        "\n",
        "    #init model with batch size, num_samples (len of data), epochs to train, and autofinds learning rate\n",
        "    model_self_sup = SimCLR(gpus = 1, max_epochs=2, arch='resnet50', dataset='', batch_size = run_params['SELF_SUPERVISED_BATCH_SIZE'], num_samples = num_samples)\n",
        "    \n",
        "    if run_params['SELF_SUPERVISED_TRAIN']:\n",
        "        logger = TensorBoardLogger(os.path.join(run_params['PATH_PREFIX'] , 'tb_logs'), name=run_params['MODEL_SAVE_NAME'])\n",
        "\n",
        "        if os.path.exists(checkpoint_resume):\n",
        "            trainer = Trainer(\n",
        "                gpus = 1,\n",
        "                logger=logger,\n",
        "                auto_scale_batch_size=True,\n",
        "                resume_from_checkpoint=checkpoint_resume\n",
        "            )\n",
        "        else:\n",
        "            checkpoint_callback = ModelCheckpoint(\n",
        "                monitor='val_loss',\n",
        "                dirpath=checkpoints_dir,\n",
        "                filename=run_params['MODEL_SAVE_NAME'],\n",
        "                save_top_k=1,\n",
        "                mode='min'\n",
        "            )\n",
        "\n",
        "            trainer = Trainer(\n",
        "                gpus = 1,\n",
        "                logger=logger,\n",
        "                auto_scale_batch_size=True,\n",
        "                callbacks=[checkpoint_callback]\n",
        "            )\n",
        "        try:\n",
        "            trainer.fit(model_self_sup, data_loader, val_loader)\n",
        "        except IndexError as e:\n",
        "            print('Finish traininig due to IndexError: ', e)\n",
        "    elif os.path.exists(checkpoint_resume):\n",
        "        model_self_sup.load_from_checkpoint(checkpoint_resume)\n",
        "    else:\n",
        "        print(f'Not checkpoint found, so it could not load model from it\\n{checkpoint_resume}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wobtRme0LuV"
      },
      "source": [
        "## Define Dataset parameters\n",
        "\n",
        "base_ds_params = {\n",
        "    # 'get_x': ColReader('Original_Filename', pref=RAW_PREPROCESS_FOLDER+'/', suff='.png'),\n",
        "    'get_x': ColReader('Raw_preprocess'),\n",
        "    # 'get_x': ColReader('Original'),\n",
        "    'item_tfms': item_tfms\n",
        "}\n",
        "\n",
        "# Specific parameters for Label Dataset \n",
        "label_ds_params = base_ds_params.copy()\n",
        "if run_params['SELF_SUPERVISED']:\n",
        "    label_ds_params['blocks'] = (ImageBlock(cls=PILImage), CategoryBlock)\n",
        "else:\n",
        "    label_ds_params['blocks'] = (ImageBlock(cls=PILImageBW), CategoryBlock)\n",
        "# label_ds_params['blocks'] = (ImageBlock(cls=PILDicom_scaled), MultiCategoryBlock)\n",
        "\n",
        "label_ds_params['get_y'] = ColReader('Target')\n",
        "label_ds_params['splitter'] = TestColSplitter(col='Dataset')\n",
        "label_ds_params['batch_tfms'] = label_transform\n",
        "\n",
        "\n",
        "# Specific parameters for Unlabel Dataset\n",
        "if run_params['SSL']:\n",
        "    unlabel_ds_params = base_ds_params.copy()\n",
        "    if run_params['SELF_SUPERVISED']:\n",
        "        unlabel_ds_params['blocks'] = (ImageBlock(cls=PILImage))\n",
        "    else:\n",
        "        unlabel_ds_params['blocks'] = (ImageBlock(cls=PILImageBW))\n",
        "    # unlabel_ds_params['blocks'] = (ImageBlock(cls=PILDicom_scaled))\n",
        "\n",
        "    unlabel_ds_params['splitter'] = RandomSplitter(0)\n",
        "\n",
        "\n",
        "## Define DataLoaders parameters\n",
        "dls_params = {\n",
        "    'bs': run_params['BATCH_SIZE'],\n",
        "    'num_workers': 0,\n",
        "    'shuffle_train': True,\n",
        "    'drop_last': True\n",
        "}\n",
        "\n",
        "if run_params['SSL']:\n",
        "    unlabel_dls_params = dls_params.copy()\n",
        "    if run_params['SSL'] == run_params['SSL_FIX_MATCH']:\n",
        "        unlabel_dls_params['bs'] = run_params['BATCH_SIZE'] * run_params['MU']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1nsP31A0LuV",
        "outputId": "9ebab4f7-ab95-42c2-fd6a-cf9ca505f92f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# DataLoaders\n",
        "print(f'==> Preparing label dataloaders')\n",
        "\n",
        "label_dl = DataBlock(**label_ds_params).dataloaders(label_df, **dls_params)\n",
        "\n",
        "if run_params['ALL_LABELS_IN_BATCH']:\n",
        "    # Create DataLoader which allows to have a minimum of samples of all the labels in each batch\n",
        "    new_dl = DataBlock(**label_ds_params).dataloaders(label_df, **dls_params, dl_type=AllLabelsInBatchDL, min_samples=run_params['MIN_SAMPLES_PER_LABEL'])\n",
        "    label_dl.train = new_dl.train\n",
        "\n",
        "elif run_params['WEIGTHED_SAMPLER']:\n",
        "    # Calculate sample weights to balance the DataLoader \n",
        "    from collections import Counter\n",
        "\n",
        "    count = Counter(label_dl.items['Target'])\n",
        "    class_weights = {}\n",
        "    for c in count:\n",
        "        class_weights[c] = 1/count[c]\n",
        "    wgts = label_dl.items['Target'].map(class_weights).values[:len(train_df)]\n",
        "\n",
        "    # Create weigthed dataloader\n",
        "    weighted_dl = DataBlock(**label_ds_params).dataloaders(label_df, **dls_params, dl_type=WeightedDL, wgts=wgts)\n",
        "    label_dl.train = weighted_dl.train\n",
        "\n",
        "if run_params['SSL']:\n",
        "    print(f'==> Preparing unlabel dataloaders')\n",
        "\n",
        "    unlabel_dls = [\n",
        "        DataBlock(\n",
        "            **unlabel_ds_params,\n",
        "            batch_tfms = batch_tfms\n",
        "        ).dataloaders(unlabel_df, **unlabel_dls_params) \n",
        "        for batch_tfms in unlabel_batch_tfms\n",
        "    ]\n",
        "    print(f'==> Preparing SSL callback')\n",
        "\n",
        "    ssl_cb = SSLCallback(*unlabel_dls, **cb_params)\n",
        "    if cbs is None:\n",
        "        cbs = [ssl_cb]\n",
        "    else:\n",
        "        cbs.append(ssl_cb)\n",
        "\n",
        "    if run_params['SSL'] == run_params['SSL_MIX_MATCH']:\n",
        "        cbs.append(MixUp(alpha=run_params['ALPHA']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG_AJc4G0LuW"
      },
      "source": [
        "# Scheduling\n",
        "if run_params['SSL'] == run_params['SSL_FIX_MATCH']:\n",
        "    sched = {'lr': SchedCos(run_params['LR'], run_params['LR']*math.cos(7*math.pi/16))}\n",
        "    cbs.append(ParamScheduler(sched))\n",
        "    opt_params = {\n",
        "        'moms': (run_params['MOMENTUM'],)*3, # 0.9 according to FixMatch paper\n",
        "        'wd': run_params['WD']\n",
        "    }\n",
        "    opt_func = SGD\n",
        "else:\n",
        "    opt_func = Adam\n",
        "    opt_params = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQqUVs--0LuX",
        "outputId": "c37579db-c3db-4315-d273-ec59f0fe9ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "77fcb5d225ca405183180d8460294c35",
            "289340db08744e62b0d8800f8cd6ccb4",
            "f21eff4e6de84ea9ad545f2e2466dd03",
            "009d4a9d4fd249df809f84b9571c376e",
            "ce9daa7195884b7f89415c7f395456c1",
            "c6a7215a40bf4cf190221f5bca0368c1",
            "451be98dd6d245a1b3473082307ec2a0",
            "1f2d2fcac8c2489bbfa1d128f0a27e0c",
            "de2f2dd9221c46b3a7bb6ff699bd7dc3",
            "8b647797d7604c228fb130375129100d",
            "ec490770badc47ae99c2101124381e21"
          ]
        }
      },
      "source": [
        "# Model\n",
        "# from fastai.vision.learner import create_head\n",
        "from fastai.layers import *\n",
        "\n",
        "print(\"==> creating model\")\n",
        "\n",
        "classes = label_df['Target'].unique()\n",
        "n_out = len(classes)\n",
        "\n",
        "if run_params['USE_SAVED_MODEL']:\n",
        "    body = create_model(run_params['MODEL'], n_out, pretrained=True, n_in=1, bn_final=True)\n",
        "\n",
        "    load_model(file=run_params['PRETRAINED_MODEL_SAVE_NAME'], model=body, opt=None, with_opt=False, device=torch.cuda.current_device(), strict=False)\n",
        "    body = body[0]\n",
        "\n",
        "    nf = num_features_model(nn.Sequential(*body.children())) * 2\n",
        "    head = create_head(nf, n_out, concat_pool=True, bn_final=True)\n",
        "        \n",
        "    model = nn.Sequential(body, head)\n",
        "    apply_init(model[1], nn.init.kaiming_normal_)\n",
        "\n",
        "elif run_params['SELF_SUPERVISED']:\n",
        "    concat_pool = True\n",
        "    for i, layer_block in enumerate(model_self_sup.children()):\n",
        "      if i == 1:\n",
        "        for layer in layer_block.children():\n",
        "          for j, layer_ in enumerate(layer.children()):\n",
        "            if j == 3:\n",
        "              nf = layer_.out_features\n",
        "    # nf = num_features_model(nn.Sequential(*model_self_sup.children())) * (2 if concat_pool else 1)\n",
        "    # head = create_head(nf, n_out, lin_ftrs=[512], ps=0.5, concat_pool=concat_pool, bn_final=True)\n",
        "\n",
        "    # Seems there is somekind of issue and nf only can be 2048\n",
        "    nf = 2048\n",
        "    layers = [\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(nf, n_out),\n",
        "        nn.BatchNorm1d(n_out, momentum=0.01)\n",
        "    ]\n",
        "    head = nn.Sequential(*layers)\n",
        "    model = nn.Sequential(model_self_sup, head)\n",
        "else:\n",
        "    model = create_model(run_params['MODEL'], n_out, pretrained=True, n_in=1, bn_final=True)\n",
        "\n",
        "# Initialize last BatchNorm bias with values reflecting the current probabilities with Softmax\n",
        "with torch.no_grad():\n",
        "    for name, param in model[-1][-1].named_parameters():\n",
        "        if 'bias' in name:\n",
        "            param.copy_(torch.as_tensor([np.log(p) for p in train_df['Target'].value_counts(normalize=True).values]))\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model = model.cuda()\n",
        "\n",
        "if run_params['SSL']:\n",
        "  if run_params['SSL'] == run_params['SSL_MIX_MATCH']:\n",
        "      loss_params['model'] = model\n",
        "\n",
        "  cbs.append(EMAModel(alpha=run_params['EMA_DECAY']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJauQa0fxJqT"
      },
      "source": [
        "if run_params['GRAD_CLIP_VAL'] is not None:\n",
        "    cbs.append(GradientClipping(clip=run_params['GRAD_CLIP_VAL']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6_7MdkV0LuY",
        "outputId": "7947b457-fffa-4f28-9bef-3da2a85de836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Loss\n",
        "print(\"==> defining loss\")\n",
        "\n",
        "if run_params['CLASS_WEIGHT']:\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_df['Target'])\n",
        "    class_weights /= class_weights.sum()\n",
        "    \n",
        "    # Correct the class weights in case of using AllLabelsInBatchDL\n",
        "    if run_params['ALL_LABELS_IN_BATCH']:\n",
        "        coef = run_params['MIN_SAMPLES_PER_LABEL'] * train_df['Target'].nunique() / run_params['BATCH_SIZE']\n",
        "        class_weights *= 1 - coef\n",
        "        class_weights += np.ones_like(class_weights) * coef / len(class_weights)\n",
        "\n",
        "    class_weights = torch.as_tensor(class_weights).float()\n",
        "    if torch.cuda.is_available():\n",
        "        class_weights = class_weights.cuda()\n",
        "else:\n",
        "    class_weights = None\n",
        "\n",
        "if run_params['SSL']:\n",
        "    if loss_params['use_SCL']:\n",
        "        loss_params['frequencies'] = torch.Tensor(train_df['Target'].value_counts())\n",
        "\n",
        "    train_criterion = SSLLoss(unlabel_dl=unlabel_dls[0], n_out=n_out, weight=class_weights, **loss_params)\n",
        "    criterion = train_criterion.Lx_criterion\n",
        "else:\n",
        "    train_criterion = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jniT_h530LuY",
        "outputId": "5886b85d-72a9-4483-98bd-343a30db5c9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Learner\n",
        "print(\"==> defining learner\")\n",
        "\n",
        "if run_params['SSL']:\n",
        "    Lx_metric = AvgMetric(func=criterion)\n",
        "    Lu_metric = AvgMetric(func=train_criterion.Lu_criterion)\n",
        "\n",
        "# Adapt metrics depending on the number of labels\n",
        "if n_out == 2:\n",
        "    average = 'binary'\n",
        "    roc_auc = RocAucBinary()\n",
        "else:\n",
        "    average = 'macro'\n",
        "    roc_auc = RocAuc()\n",
        "\n",
        "metrics = [\n",
        "    error_rate,\n",
        "    BalancedAccuracy(),\n",
        "    # roc_auc,\n",
        "    FBeta(0.5, average=average),\n",
        "    F1Score(average=average),\n",
        "    FBeta(2, average=average),\n",
        "    Precision(average=average),\n",
        "    Recall(average=average)\n",
        "]\n",
        "\n",
        "learn = Learner(label_dl, model, loss_func=train_criterion, opt_func=opt_func, **opt_params, lr=run_params['LR'], metrics=metrics, cbs=cbs)\n",
        "learn.recorder.train_metrics = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IELUP7RbxJqU"
      },
      "source": [
        "# learn.freeze()\n",
        "# learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4WrDDE40LuY"
      },
      "source": [
        "# learn.unfreeze()\n",
        "# learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChmU3jEQxJqU",
        "outputId": "123df7b5-d26c-4d04-f698-3ecb510d06f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "learn.fine_tune(10, run_params['LR'], freeze_epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1zXqp-3xJqV",
        "outputId": "b983c60c-8111-44e7-b24f-0d4ae92dacd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "learn.fine_tune(10, run_params['LR'], freeze_epochs=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksufRdRExJqV",
        "outputId": "2c3cfc7b-7d63-4d93-82a7-f8e47a5b3f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        }
      },
      "source": [
        "learn.fine_tune(10, run_params['LR'], freeze_epochs=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO9KqOTexJqV"
      },
      "source": [
        "learn.fine_tune(10, run_params['LR'], freeze_epochs=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mms9Zy1cxJqV"
      },
      "source": [
        "if run_params['SAVE_MODEL']:\n",
        "\n",
        "    if not os.path.exists(run_params['MODELS_FOLDER']):\n",
        "        os.makedirs(run_params['MODELS_FOLDER'])\n",
        "\n",
        "    save_model(file=run_params['MODEL_SAVE_PATH'], model=learn.model, opt=learn.opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR8RGEDxxJqW",
        "outputId": "dd2d0bb7-7298-4eb7-fb0d-fd68f0a8cd83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "source": [
        "# Select only the top K images with largest loss\n",
        "\n",
        "from fastai.interpret import ClassificationInterpretation\n",
        "# from fastai2_extensions.interpret.all import *\n",
        "# from fastai_amalgam.interpret.all import *\n",
        "\n",
        "k = 9\n",
        "largest = True\n",
        "dls_idx = 1\n",
        "\n",
        "preds, targs, decoded, all_losses = learn.get_preds(dls_idx, with_decoded=True, with_loss=True)\n",
        "losses, idx = all_losses.topk(ifnone(k, len(all_losses)), largest=largest)\n",
        "\n",
        "top_losses_dl = learn.dls.test_dl(learn.dls[dls_idx].items.iloc[idx])\n",
        "top_losses_dl.bs = len(idx)\n",
        "\n",
        "interp = ClassificationInterpretation(\n",
        "    learn.dls[dls_idx],\n",
        "    inputs=first(top_losses_dl),\n",
        "    preds=preds[idx],\n",
        "    targs=targs[idx],\n",
        "    decoded=decoded[idx],\n",
        "    losses=losses,\n",
        "    # *tuple(map(lambda x: x[idx], learn.get_preds(dls_idx, with_input=True, with_loss=True, with_decoded=True)))\n",
        ")\n",
        "interp.plot_top_losses(k=k, cmap=plt.cm.bone)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7uXtOd0xJqW",
        "outputId": "e646f28c-8777-476a-d248-20545c399f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "dls_idx = 2\n",
        "\n",
        "preds, targs, decoded, all_losses = learn.get_preds(dls_idx, with_decoded=True, with_loss=True)\n",
        "max_preds, outs = torch.max(preds, axis=1)\n",
        "\n",
        "for metric in metrics:\n",
        "    try:\n",
        "        metric_name = metric.name\n",
        "    except AttributeError:\n",
        "        metric_name = metric.__name__\n",
        "\n",
        "    try:\n",
        "        print(metric_name, ':', metric(preds, targs))\n",
        "    except AssertionError:\n",
        "        print(metric_name, ':', metric(outs, targs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndGNZbX-xJqW",
        "outputId": "f11e9256-a92c-4a62-a20f-544e3ce271e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Plot GradCAM for the top K images with largest loss\n",
        "\n",
        "from fastai_amalgam.interpret.gradcam import gradcam\n",
        "\n",
        "dls_idx = 1\n",
        "\n",
        "for i in idx:\n",
        "    gcam = gradcam(learn, learn.dls[dls_idx].items.iloc[i.numpy()]['Raw_preprocess'], labels=['0', '1'], show_original=True, cmap=plt.cm.bone)\n",
        "    display(gcam)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmXDKqCHxJqX",
        "outputId": "fab8009a-c5e7-46b5-a3f5-fff59f4a0252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Plot GradCAM for the true positive images\n",
        "\n",
        "from fastai_amalgam.interpret.gradcam import gradcam\n",
        "\n",
        "dls_idx = 0\n",
        "label_idxs = learn.dls[dls_idx].items[learn.dls[dls_idx].items['Target'] != '0'].index\n",
        "\n",
        "for i in label_idxs:\n",
        "    gcam = gradcam(learn, learn.dls[dls_idx].items.loc[i, 'Raw_preprocess'], labels=['0', '1'], show_original=True, cmap=plt.cm.bone)\n",
        "    display(gcam)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs4EuhEgxJqX",
        "outputId": "a0ad152a-b5c3-4a40-addf-c0c933ca4f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "# Plot GradCAM for the true positive images\n",
        "\n",
        "from fastai_amalgam.interpret.gradcam import gradcam\n",
        "\n",
        "dls_idx = 1\n",
        "label_idxs = learn.dls[dls_idx].items[learn.dls[dls_idx].items['Target'] != '0'].index\n",
        "\n",
        "for i in label_idxs:\n",
        "    gcam = gradcam(learn, learn.dls[dls_idx].items.loc[i, 'Raw_preprocess'], labels=['0', '1'], show_original=True, cmap=plt.cm.bone)\n",
        "    display(gcam)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vVrF2_x86rO",
        "outputId": "a8ade845-9878-4a94-b860-538806bdab53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "# Plot GradCAM for the true positive images\r\n",
        "\r\n",
        "from fastai_amalgam.interpret.gradcam import gradcam\r\n",
        "\r\n",
        "dls_idx = 2\r\n",
        "label_idxs = learn.dls[dls_idx].items[learn.dls[dls_idx].items['Target'] != '0'].index\r\n",
        "\r\n",
        "for i in label_idxs:\r\n",
        "    gcam = gradcam(learn, learn.dls[dls_idx].items.loc[i, 'Raw_preprocess'], labels=['0', '1'], show_original=True, cmap=plt.cm.bone)\r\n",
        "    display(gcam)\r\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}