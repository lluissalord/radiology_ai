{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.11 64-bit ('radiology_ai': conda)",
   "metadata": {
    "interpreter": {
     "hash": "73c679d2cc001810287e7be6e0757dc766f509031127652202e04048c8fced99"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define if we are on Colab and mount drive { display-mode: \"form\" }\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title (COLAB ONLY) Clone GitHub repo { display-mode: \"form\" }\n",
    "\n",
    "if IN_COLAB:\n",
    "  !git clone https://github.com/lluissalord/radiology_ai.git\n",
    "\n",
    "  %cd radiology_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup environment and Colab general variables { display-mode: \"form\" }\n",
    "%%capture\n",
    "%run colab_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Move images from Drive to temporary folder here to be able to train models { display-mode: \"form\" }\n",
    "%%capture\n",
    "%run move_raw_preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.callback import *\n",
    "from fastai.data.block import *\n",
    "from fastai.data.transforms import *\n",
    "from fastai.medical.imaging import *\n",
    "from fastai.vision.data import *\n",
    "from fastai.vision.augment import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import concat_templates, TestColSplitter\n",
    "\n",
    "# Required to load DICOM on the fly\n",
    "from preprocessing import *\n",
    "from utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.15\n",
    "VALID_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "RESIZE = 512\n",
    "\n",
    "HIST_CLIPPING = True\n",
    "KNEE_LOCALIZER = True\n",
    "CLAHE_SCALED = True\n",
    "HIST_SCALED = False\n",
    "HIST_SCALED_SELF = True\n",
    "\n",
    "BINARY_CLASSIFICATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "\n",
    "item_tfms = []\n",
    "\n",
    "if HIST_CLIPPING:\n",
    "    item_tfms.append(XRayPreprocess())\n",
    "    \n",
    "if KNEE_LOCALIZER:\n",
    "    item_tfms.append(KneeLocalizer(KNEE_SVM_MODEL_PATH))\n",
    "\n",
    "item_tfms.append(Resize(RESIZE, method=ResizeMethod.Pad, pad_mode=PadMode.Zeros))\n",
    "# item_tfms.append(RandomResizedCrop(RANDOM_RESIZE_CROP))\n",
    "\n",
    "batch_tfms=[*aug_transforms(), Normalize()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  df = concat_templates(organize_folder, excel=True)\n",
    "  df.to_excel(\n",
    "      os.path.join(PATH_PREFIX, 'all.xlsx'),\n",
    "      index=False\n",
    "  )\n",
    "else:\n",
    "  df = pd.read_excel(os.path.join(PATH_PREFIX, 'all.xlsx'), dtype={'ID':'string','Target':'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "relation_df = pd.read_csv(os.path.join(PATH_PREFIX, 'relation.csv'))\n",
    "relation_df = relation_df.set_index('Filename')\n",
    "\n",
    "final_df = df.set_index('ID').merge(relation_df, left_index=True, right_index=True)\n",
    "final_df['ID'] = final_df.index.values\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "final_df['Raw_preprocess'] = final_df['Original_Filename'].apply(lambda filename: os.path.join(raw_preprocess_folder, filename + '.png'))\n",
    "\n",
    "unlabel_df = final_df[df['Target'].isnull()].reset_index(drop=True)\n",
    "label_df = final_df[df['Target'].notnull()].reset_index(drop=True)\n",
    "if BINARY_CLASSIFICATION:\n",
    "  label_df['Target'] = (label_df['Target'] != '0').astype(int).astype('string')\n",
    "\n",
    "try:\n",
    "  train_df, test_df = train_test_split(label_df, test_size=TEST_SIZE, shuffle=True, stratify=label_df['Target'], random_state=SEED)\n",
    "except ValueError:\n",
    "  train_df, test_df = train_test_split(label_df, test_size=TEST_SIZE, shuffle=True, random_state=SEED)\n",
    "\n",
    "try:\n",
    "  train_df, val_df = train_test_split(train_df, test_size=VALID_SIZE/(1-TEST_SIZE), shuffle=True, stratify=train_df['Target'], random_state=SEED)\n",
    "except ValueError:\n",
    "  train_df, val_df = train_test_split(train_df, test_size=VALID_SIZE/(1-TEST_SIZE), shuffle=True, random_state=SEED)\n",
    "\n",
    "label_df.loc[train_df.index, 'Dataset'] = 'train'\n",
    "label_df.loc[val_df.index, 'Dataset'] = 'valid'\n",
    "label_df.loc[test_df.index, 'Dataset'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram scaling DICOM on the fly\n",
    "\n",
    "if CLAHE_SCALED:\n",
    "    item_tfms.append(CLAHE_Transform(grayscale=not SELF_SUPERVISED))\n",
    "elif HIST_SCALED:\n",
    "    if HIST_SCALED_SELF:\n",
    "        bins = None\n",
    "    else:\n",
    "        # bins = init_bins(fnames=L(list(final_df['Original'].values)), n_samples=100)\n",
    "        bins = init_bins(fnames=L(list(final_df['Raw_preprocess'].values)), n_samples=100, isDCM=False)\n",
    "    # item_tfms.append(HistScaled(bins))\n",
    "    item_tfms.append(HistScaled_all(bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = DataBlock(\n",
    "    blocks=(ImageBlock(cls=PILImageBW), MultiCategoryBlock),\n",
    "    get_x=ColReader('Original_Filename', pref=raw_preprocess_folder+'/', suff='.png'), \n",
    "    get_y=ColReader('Target'),\n",
    "    splitter=TestColSplitter(col='Dataset'),\n",
    "    item_tfms=item_tfms,\n",
    "    batch_tfms=batch_tfms,\n",
    ").dataloaders(label_df, bs=BATCH_SIZE, num_workers=0)\n",
    "\n",
    "label_data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def focal_loss(input, target, reduction='mean', beta=0.5, gamma=2., eps=1e-7, **kwargs):\n",
    "    n = input.size(0)\n",
    "    iflat = torch.sigmoid(input).view(n, -1).clamp(eps, 1-eps)\n",
    "    tflat = target.view(n, -1)\n",
    "    focal = -(beta*tflat*(1-iflat).pow(gamma)*iflat.log()+\n",
    "             (1-beta)*(1-tflat)*iflat.pow(gamma)*(1-iflat).log()).mean(-1)\n",
    "    if torch.isnan(focal.mean()) or torch.isinf(focal.mean()):\n",
    "        pdb.set_trace()\n",
    "    if reduction == 'mean':\n",
    "        return focal.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return focal.sum()\n",
    "    else:\n",
    "        return focal\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, beta=0.5, gamma=2., reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, input, target, **kwargs):\n",
    "        return focal_loss(input, target, beta=self.beta, gamma=self.gamma, reduction=self.reduction, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callbacks that will be used during training\n",
    "callback_fns = [\n",
    "        MixUp(),\n",
    "        # partial(OverSamplingCallback),\n",
    "        # ShowGraph\n",
    "    ]\n",
    "roc_auc = RocAuc()\n",
    "f1_score = F1ScoreMulti(average='macro')\n",
    "precision = PrecisionMulti(average='macro')\n",
    "recall = RecallMulti(average='macro')\n",
    "learn = cnn_learner(\n",
    "    label_data,\n",
    "    resnet18,\n",
    "    loss_func=FocalLoss(),\n",
    "    metrics=[\n",
    "        accuracy_multi,\n",
    "        # roc_auc, # Not able if in some step/epoch there is only one class\n",
    "        f1_score,\n",
    "        precision,\n",
    "        recall\n",
    "    ],\n",
    "    callback_fns=callback_fns\n",
    ")\n",
    "\n",
    "# Regularization by using float precision of 16 bits\n",
    "# This helps to not overfit because is more difficult to \"memorize\" images, but enough to learn\n",
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(10, 0.05, freeze_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(max_n=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = Interpretation.from_learner(learn, 1)\n",
    "losses, idx = interp.top_losses()\n",
    "interp.plot_top_losses(25, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}